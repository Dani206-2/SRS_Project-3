---
title: "Appendix"
output: pdf_document
---
# Initial model without interaction terms
```{r}



data_m<-c(1, 1, 1, 15, 0, 3, 19, 54, 
                 4, 19, 62, 464, 76, 703, 1006)

#**** Coefficients: Indicator variables for the 4 Lists ******
# LA: Local Authority
# NGO: Non Governmental Organization
# PF: Police Force
# GO: Governmental Organization

LA<- c(rep(1,8),rep(0,7))
NGO<- c(rep(1,4),rep(0,4),rep(1,4),rep(0,3))
PF<-c(rep(c(1,0,1,0),3),c(1,0,1))
GO<-c(rep(c(1,1,0,0),3),c(1,1,0))

df<-data.frame(cbind(data_m,LA,NGO,PF,GO))
#***** 1.  Initial model ***********

model<-glm(data_m~LA+NGO+PF+GO, family=poisson(link="log"))

summary(model)
```
# Model with interaction terms: using all interaction terms

```{r}


model <- glm(data_m~LA+NGO+PF+GO+(LA+NGO+PF+GO)^2, family=poisson(link="log"))

summary(model)

```


# Model with interaction terms: Relative Goodness of Fit

```{r}

# Terms are added one by one and best model is chosen based on AIC
step_model<-step(model)
summary(step_model)
qchisq(p=0.05,df=7,lower.tail=FALSE)

```


# Assessing Absolute Goodness of Fit
The residual deviance is 11.341 for 7 degrees of freedom. Compared with Chi-Sq
$\alpha$=0.05 critical value for 7 degrees of freedom (14.067), we don't
reject the null hypothesis, hence no evidence of lack of fit.

The change in deviance is 6047.262-11.341 = 6035.921. 
Comparing this with the Ch-sq 5% critical value for 14-7=7 degrees of freedom, we can reject the null hypothesis of an intercept only model and conclude that our chosen model fits the data much better compared to an intercept only model.

We can also call the anova function to see how the deviance changed for the addition
of each term

```{r}
anova(step_model)
```

# Final model
```{r}
final_model<-glm(data_m~LA+NGO+PF+GO+(LA*NGO)+(LA*PF)+(NGO*GO), family=poisson(link="log"))
summary(final_model)
```

## Estimate of total population 
$exp(\beta_0)$ + sum(data from lists)
```{r}
exp(summary(final_model)$coefficients[1,1])+sum(data_m)
```

## Coefficients from the model
```{r}
summary(final_model)$coefficients
```


# Pearson Residual plots
```{r}

pearson_residual <- residuals(step_model, type="pearson")
library(ggplot2)


# Create data frame for ggplot
df <- data.frame(fitted = step_model$fitted.values,
                 pearson_residual = pearson_residual)

# Pearson residuals plot
p1 <- ggplot(df, aes(x = fitted, y = pearson_residual)) +
  geom_point(color="steelblue")+
  geom_hline(aes(yintercept=0),color="#F8766D")+
  labs(x = "Fitted values (log scale)", y = "Pearson residuals") +
  theme_bw()

# QQ plot of Pearson residuals
p2 <- ggplot(df, aes(sample = pearson_residual)) +
  geom_qq(color="steelblue") +
  stat_qq_line(color="#F8766D") +
  labs(x = "Theoretical quantiles", y = "Pearson residuals") +
  theme_bw()

# Combine the plots
gridExtra::grid.arrange(p1, p2, ncol = 2)


```


Checking which datapoint the largest residual corresponds to,
```{r}
# Checking fitted values against original
cbind(step_model$fitted.values,data_m,pearson_residual)
```


# Confidence intervals: Profile likelihood

The PL method has a few differences from the regular confidence interval.
It first evaluates the Profile function for a parameter. The profile function
takes a parameter of interest and then maximizes the likelihood with respect
to it, keeping values of other parameters fixed. The maximum value of the 
profile function is further used to compute likelihood ratio statistics
and compared with the asymptotic chi-sq distribution for confidence intervals.
For more on Profile Likelihood, please see Royston, 2007 given in 
references

```{r}
conf<-confint(final_model,level=0.95)
conf
```


For the confidence intervals of the total population, 
exp(intervals for beta_0)+sum(data)
```{r}
exp(confint(final_model,level=0.95)[1,1:2])+sum(data_m)
```











