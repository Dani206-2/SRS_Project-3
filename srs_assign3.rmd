---
title: "SRS_Assignment3"
output: pdf_document
date: "2023-03-23"
---
```{r}



data_m<-c(1, 1, 1, 15, 0, 3, 19, 54, 
                 4, 19, 62, 464, 76, 703, 1006)

#**** Coefficients: Indicator variables for the 4 Lists ******
# LA: Local Authority
# NGO: Non Governmental Organization
# PF: Police Force
# GO: Governmental Organization

LA<- c(rep(1,8),rep(0,7))
NGO<- c(rep(1,4),rep(0,4),rep(1,4),rep(0,3))
PF<-c(rep(c(1,0,1,0),3),c(1,0,1))
GO<-c(rep(c(1,1,0,0),3),c(1,1,0))

df<-data.frame(cbind(data_m,LA,NGO,PF,GO))
#***** 1.  Initial model ***********

```


```{r}
#**** 2. Model with interaction terms: using all interaction terms *****

model <- glm(data_m~LA+NGO+PF+GO+(LA+NGO+PF+GO)^2, family=poisson(link="log"))

summary(model)

```

# ```{r}
# # Estimate of the total population size
# exp(summary(model)$coefficients[1,1])+sum(data_m)
# 
# b0<-summary(model)$coefficients[1,1]
# b0_se<-summary(model)$coefficients[1,2]
# 
# # Confidence Interval for unobserved population
# cat('\nThe 95% confidence interval for the unobserved population is ',
#     '(',
#     exp(b0-1.96*b0_se),
#     ',',
#     exp(b0+1.96*b0_se),
#     ')')
# ```


```{r}
#**** 3. Model with interaction terms: Adding terms based on AIC ****

step_model<-step(model)
summary(step_model)
```
The residual deviance is 11.341 for 7 degrees of freedom. The change in deviance is 6047.262-11.341 = 6035.921. 
Comparing this with the Ch-sq critical value for 14-7=7 degrees of freedom, we can reject the null hypothesis and conclude
that our chosen model fits the data much better compared to an intercept only model

```{r}
# Just checking again; we can see that resid deviance reduces for each term added
anova(step_model)
```


```{r}
# #**** 4. Correlations btwn variables as a criterion to choose interactions ****
# # Looking at correlations between variables
# #install.packages("psych")
# library(psych)
# 
#   one<-which(df$LA==0 & df$NGO==0)
#   two<-which(df$LA==1&df$NGO==0)
#   three<-which(df$LA==0&df$NGO==1)
#   four<-which(df$LA==1&df$NGO==1)
# 
#   pair<-matrix(c(sum(df$data_m[one]), sum(df$data_m[two]),
#                  sum(df$data_m[three]), sum(df$data_m[four])), nrow=2)
# 
#   tetrachoric(pair)
```


```{r}
#**** 5. Goodness of fit for selected model ****
pearson_residual <- residuals(step_model, type="pearson")
ssr <- sum(pearson_residual^2) 
pchisq(ssr, 7)
```

# Final model
```{r}
final_model<-glm(data_m~LA+NGO+PF+GO+(LA*NGO)+(LA*PF)+(NGO*GO), family=poisson(link="log"))
```






```{r}
#**** 6. Checking model assumptions ****

library(ggplot2)


# Create data frame for ggplot
df <- data.frame(fitted = log(step_model$fitted.values),
                 pearson_residual = pearson_residual)

# Pearson residuals plot
p1 <- ggplot(df, aes(x = fitted, y = pearson_residual)) +
  geom_point(color="steelblue")+
  geom_hline(aes(yintercept=0),color="#F8766D")+
  labs(x = "Fitted values (log scale)", y = "Pearson residuals") +
  theme_bw()

# QQ plot of Pearson residuals
p2 <- ggplot(df, aes(sample = pearson_residual)) +
  geom_qq(color="steelblue") +
  stat_qq_line(color="#F8766D") +
  labs(x = "Theoretical quantiles", y = "Pearson residuals") +
  theme_bw()

# Combine the plots
gridExtra::grid.arrange(p1, p2, ncol = 2)


```

# ```{r}
# #**** 7. Confidence Interval for total N  ****
# # Final estimate of the total population size
# exp(summary(step_model)$coefficients[1,1])+sum(data_m)
# 
# # Final confidence interval for the total population size N
# b0_N<-summary(step_model)$coefficients[1,1]
# b0_se_N<-summary(step_model)$coefficients[1,2]
# 
# # Confidence Interval for the total population size N
# cat('\nThe 95% confidence interval for the total population size N is ',
#     '(',
#     exp(b0_N-1.96*b0_se_N)+sum(data_m),
#     ',',
#     exp(b0_N+1.96*b0_se_N)+sum(data_m),
#     ')')
# 
# ```


```{r}
prof<-profile(final_model,level=0.95)
```


# Profile Likelihood method for the confidence interval
```{r}

conf<-confint(profile(final_model,level=0.95))
conf
```
#Checking using the model used in that paper to see if we can get the same freaking thing.

After running this cell, some of the varnames get replaced so make sure to run the first cell of this markdown
once more for running the model used in our report

The paper uses some other function to maximize the loglikelihood, which is why I think the values here dont'
exactly match up. But the confidence interval estimates are close enough
```{r}

LA<- c(1,0,0,0,0,1,1,1,rep(0,7),1,1,1)
NGO<- c(0,1,0,0,0,1,0,0,1,1,1,0,0,0,1,1,1,1)
PF<-c(0,0,1,0,0,0,1,0,1,0,0,1,1,0,1,1,0,1)
GO<-c(0,0,0,1,0,0,0,1,0,1,0,1,0,1,1,0,1,1)
GP<-c(0,0,0,0,1,0,0,0,0,0,1,0,1,1,0,0,0,0)
data<-c(54, 463, 995, 695, 316, 15, 19, 3, 62, 19, 1, 76, 11, 8, 4, 1, 1, 1)


model_paper<-glm(data~LA+NGO+PF+GO+(LA*NGO)+(NGO*GP)+(PF*GP)+(LA*PF)+(GO*GP)+
                   (NGO*GO), family=poisson(link="log"))

summary(model_paper)
```
For the confidence intervals of the total population, exp(intervals for beta_0)+sum(data)
```{r}
exp(confint(profile(model_paper,level=0.95))[1,1:2])+sum(data)
```
